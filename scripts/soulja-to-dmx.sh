#!/bin/bash
# Soulja â†’ DMX Handoff Script
# Transfers test results to DMX for quality review

set -e

# Configuration
PROJECT_DIR="${1:-.}"
OPS_BOARD="${PROJECT_DIR}/AGENT_OPS_BOARD.md"
LEARNINGS="${PROJECT_DIR}/AGENT_LEARNINGS.md"
TEST_RESULTS="${PROJECT_DIR}/.test-results.tmp"

# Colors
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
RED='\033[0;31m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

echo -e "${GREEN}ğŸ”„ Soulja â†’ DMX Handoff${NC}"
echo "Project: ${PROJECT_DIR}"
echo ""

# Validate ops board exists
if [ ! -f "${OPS_BOARD}" ]; then
    echo -e "${RED}âŒ Error: Ops board not found${NC}"
    echo "Expected: ${OPS_BOARD}"
    exit 1
fi

# Extract test tasks from ops board
echo -e "${YELLOW}ğŸ“‹ Checking test task status...${NC}"

SOULJA_TASKS=$(grep -E "\| T-[0-9]+ \|.*\| @soulja \|" "${OPS_BOARD}" || true)

if [ -z "${SOULJA_TASKS}" ]; then
    echo -e "${RED}âŒ Error: No Soulja tasks found in ops board${NC}"
    exit 1
fi

echo -e "${GREEN}âœ“ Found $(echo \"${SOULJA_TASKS}\" | wc -l | xargs) Soulja tasks${NC}"

# Run tests and capture results
echo ""
echo -e "${YELLOW}ğŸ§ª Running test suite...${NC}"

# Unit tests
echo -e "${BLUE}Running unit tests...${NC}"
UNIT_TEST_OUTPUT=$(cargo test --workspace 2>&1 || true)
UNIT_TEST_EXIT_CODE=$?

# Count test results
UNIT_TESTS_PASSED=$(echo "${UNIT_TEST_OUTPUT}" | grep -oE "[0-9]+ passed" | grep -oE "[0-9]+" || echo "0")
UNIT_TESTS_FAILED=$(echo "${UNIT_TEST_OUTPUT}" | grep -oE "[0-9]+ failed" | grep -oE "[0-9]+" || echo "0")

if [ "${UNIT_TEST_EXIT_CODE}" -eq 0 ]; then
    echo -e "${GREEN}âœ“ Unit tests passed: ${UNIT_TESTS_PASSED}${NC}"
else
    echo -e "${RED}âœ— Unit tests failed: ${UNIT_TESTS_FAILED}${NC}"
fi

# Integration tests
echo -e "${BLUE}Running integration tests...${NC}"
INTEGRATION_TEST_OUTPUT=$(cargo test --test '*' 2>&1 || true)
INTEGRATION_TEST_EXIT_CODE=$?

INTEGRATION_TESTS_PASSED=$(echo "${INTEGRATION_TEST_OUTPUT}" | grep -oE "[0-9]+ passed" | grep -oE "[0-9]+" || echo "0")
INTEGRATION_TESTS_FAILED=$(echo "${INTEGRATION_TEST_OUTPUT}" | grep -oE "[0-9]+ failed" | grep -oE "[0-9]+" || echo "0")

if [ "${INTEGRATION_TEST_EXIT_CODE}" -eq 0 ]; then
    echo -e "${GREEN}âœ“ Integration tests passed: ${INTEGRATION_TESTS_PASSED}${NC}"
else
    echo -e "${RED}âœ— Integration tests failed: ${INTEGRATION_TESTS_FAILED}${NC}"
fi

# Test coverage (if cargo-tarpaulin is installed)
echo -e "${BLUE}Checking test coverage...${NC}"
if command -v cargo-tarpaulin &> /dev/null; then
    COVERAGE_OUTPUT=$(cargo tarpaulin --workspace --out Stdout 2>&1 || true)
    COVERAGE_PERCENTAGE=$(echo "${COVERAGE_OUTPUT}" | grep -oE "[0-9]+\.[0-9]+%" | tail -1 || echo "0.0%")
    echo -e "${GREEN}âœ“ Test coverage: ${COVERAGE_PERCENTAGE}${NC}"
else
    COVERAGE_PERCENTAGE="N/A (cargo-tarpaulin not installed)"
    echo -e "${YELLOW}âš  Test coverage tool not available${NC}"
fi

# WASM tests (if wasm-pack is available)
WASM_TEST_STATUS="N/A"
if [ -d "${PROJECT_DIR}/levite-web" ]; then
    echo -e "${BLUE}Running WASM tests...${NC}"
    if command -v wasm-pack &> /dev/null; then
        WASM_TEST_OUTPUT=$(wasm-pack test --headless --chrome "${PROJECT_DIR}/levite-web" 2>&1 || true)
        WASM_TEST_EXIT_CODE=$?

        if [ "${WASM_TEST_EXIT_CODE}" -eq 0 ]; then
            echo -e "${GREEN}âœ“ WASM tests passed${NC}"
            WASM_TEST_STATUS="âœ… Passed"
        else
            echo -e "${RED}âœ— WASM tests failed${NC}"
            WASM_TEST_STATUS="âŒ Failed"
        fi
    else
        echo -e "${YELLOW}âš  wasm-pack not available${NC}"
    fi
fi

# Save test results summary
{
    echo "# Test Results Summary"
    echo "**Date**: $(date +"%Y-%m-%d %H:%M:%S")"
    echo ""
    echo "## Unit Tests"
    echo "- Passed: ${UNIT_TESTS_PASSED}"
    echo "- Failed: ${UNIT_TESTS_FAILED}"
    echo "- Status: $([ ${UNIT_TEST_EXIT_CODE} -eq 0 ] && echo 'âœ… Passed' || echo 'âŒ Failed')"
    echo ""
    echo "## Integration Tests"
    echo "- Passed: ${INTEGRATION_TESTS_PASSED}"
    echo "- Failed: ${INTEGRATION_TESTS_FAILED}"
    echo "- Status: $([ ${INTEGRATION_TEST_EXIT_CODE} -eq 0 ] && echo 'âœ… Passed' || echo 'âŒ Failed')"
    echo ""
    echo "## Coverage"
    echo "- Percentage: ${COVERAGE_PERCENTAGE}"
    echo "- Target: 85%"
    echo ""
    echo "## WASM Tests"
    echo "- Status: ${WASM_TEST_STATUS}"
} > "${TEST_RESULTS}"

# Determine if tests passed quality gate
TESTS_PASSED=false
if [ "${UNIT_TEST_EXIT_CODE}" -eq 0 ] && [ "${INTEGRATION_TEST_EXIT_CODE}" -eq 0 ]; then
    TESTS_PASSED=true
fi

# Update ops board with test results
echo ""
echo -e "${YELLOW}ğŸ“ Updating ops board with test results...${NC}"

TIMESTAMP=$(date +"%Y-%m-%d %H:%M")

# Mark Soulja tasks as complete
{
    while IFS= read -r line; do
        if echo "${line}" | grep -q "\| @soulja \|"; then
            # Replace status with âœ… Done or âŒ Failed
            if [ "${TESTS_PASSED}" = true ]; then
                echo "${line}" | sed 's/| ğŸŸ¢ Ready |/| âœ… Done |/g' | sed 's/| ğŸŸ¡ In Progress |/| âœ… Done |/g'
            else
                echo "${line}" | sed 's/| ğŸŸ¢ Ready |/| âŒ Failed |/g' | sed 's/| ğŸŸ¡ In Progress |/| âŒ Failed |/g'
            fi
        else
            echo "${line}"
        fi
    done < "${OPS_BOARD}"
} > "${OPS_BOARD}.tmp"

mv "${OPS_BOARD}.tmp" "${OPS_BOARD}"

# Add DMX review task if tests passed
if [ "${TESTS_PASSED}" = true ]; then
    echo -e "${GREEN}âœ“ All tests passed - creating DMX review task${NC}"

    # Generate next task ID
    LAST_TASK_ID=$(grep -oE "T-[0-9]+" "${OPS_BOARD}" | sed 's/T-//' | sort -n | tail -1)
    NEXT_TASK_ID=$((LAST_TASK_ID + 1))

    DMX_REVIEW_SECTION="
### Quality Review (Added ${TIMESTAMP})

| Task ID | Task | Assigned | Priority | Status | Files |
|---------|------|----------|----------|--------|-------|
| T-${NEXT_TASK_ID} | Run Clippy linter (zero warnings) | @dmx | ğŸ”´ Critical | ğŸŸ¢ Ready | cargo clippy |
| T-$((NEXT_TASK_ID + 1)) | Verify code formatting | @dmx | ğŸ”´ Critical | ğŸŸ¢ Ready | rustfmt --check |
| T-$((NEXT_TASK_ID + 2)) | Run security scan (Semgrep) | @dmx | ğŸ”´ Critical | ğŸŸ¢ Ready | semgrep --config auto |
| T-$((NEXT_TASK_ID + 3)) | Approve PR or request changes | @dmx | ğŸ”´ Critical | ğŸŸ¢ Ready | gh pr review |

**Test Results**: ${TEST_RESULTS}
**Coverage**: ${COVERAGE_PERCENTAGE}
"

    # Append to ops board
    {
        sed '/## Active Tasks/,/^## / {/^## Active Tasks/p; /^## /!d; /^## Active Tasks/d}' "${OPS_BOARD}"
        echo "${DMX_REVIEW_SECTION}"
        echo ""
        sed -n '/## Active Tasks/,$ {/## Active Tasks/d; p}' "${OPS_BOARD}"
    } > "${OPS_BOARD}.tmp"

    mv "${OPS_BOARD}.tmp" "${OPS_BOARD}"
else
    echo -e "${RED}âœ— Tests failed - DMX review blocked${NC}"
fi

echo -e "${GREEN}âœ“ Ops board updated${NC}"

# Update learnings
echo ""
echo -e "${YELLOW}ğŸ“š Updating Agent Learnings...${NC}"

TEST_SUMMARY="Unit: ${UNIT_TESTS_PASSED} passed, ${UNIT_TESTS_FAILED} failed. Integration: ${INTEGRATION_TESTS_PASSED} passed, ${INTEGRATION_TESTS_FAILED} failed. Coverage: ${COVERAGE_PERCENTAGE}"

LEARNING_ENTRY="| ${TIMESTAMP} | Testing complete - $([ ${TESTS_PASSED} = true ] && echo 'ready for review' || echo 'fixes needed') | ${TEST_SUMMARY} | @soulja | ${TEST_RESULTS} |"

# Add to learnings file
if grep -q "## Testing Results" "${LEARNINGS}"; then
    LINE_NUM=$(grep -n "## Testing Results" "${LEARNINGS}" | head -1 | cut -d: -f1)
    TABLE_START=$((LINE_NUM + 3))

    sed -i.bak "${TABLE_START}i\\
${LEARNING_ENTRY}
" "${LEARNINGS}"
    rm "${LEARNINGS}.bak"

    echo -e "${GREEN}âœ“ Agent Learnings updated${NC}"
else
    echo -e "${YELLOW}âš  Warning: Could not find Testing Results section in learnings${NC}"
fi

# Notify DMX or report failure
echo ""
if [ "${TESTS_PASSED}" = true ]; then
    echo -e "${GREEN}âœ… Handoff Complete - Tests Passed${NC}"
    echo ""
    echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
    echo -e "${YELLOW}@dmx${NC} has been assigned quality review tasks:"
    echo ""
    echo "Test Results:"
    echo "  âœ… Unit Tests: ${UNIT_TESTS_PASSED} passed"
    echo "  âœ… Integration Tests: ${INTEGRATION_TESTS_PASSED} passed"
    echo "  ğŸ“Š Coverage: ${COVERAGE_PERCENTAGE}"
    echo "  ğŸŒ WASM Tests: ${WASM_TEST_STATUS}"
    echo ""
    echo "Next steps for DMX:"
    echo "  1. Review test results: ${TEST_RESULTS}"
    echo "  2. Run cargo clippy -- -D warnings"
    echo "  3. Run rustfmt --check src/**/*.rs"
    echo "  4. Run semgrep --config auto src/"
    echo "  5. Review code changes: git diff"
    echo "  6. Approve or request changes: gh pr review"
    echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
else
    echo -e "${RED}âŒ Testing Failed - Review Required${NC}"
    echo ""
    echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
    echo -e "${YELLOW}@ox${NC} must fix failing tests:"
    echo ""
    echo "Test Results:"
    echo "  âŒ Unit Tests: ${UNIT_TESTS_FAILED} failed"
    echo "  âŒ Integration Tests: ${INTEGRATION_TESTS_FAILED} failed"
    echo ""
    echo "Next steps:"
    echo "  1. Review test output: ${TEST_RESULTS}"
    echo "  2. Fix failing tests"
    echo "  3. Re-run: bash ox-to-soulja.sh"
    echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
fi
echo ""

# Summary
echo "Summary:"
echo "  Soulja Tasks: $(echo \"${SOULJA_TASKS}\" | wc -l | xargs)"
echo "  Test Status: $([ ${TESTS_PASSED} = true ] && echo 'âœ… Passed' || echo 'âŒ Failed')"
echo "  Unit Tests: ${UNIT_TESTS_PASSED} passed, ${UNIT_TESTS_FAILED} failed"
echo "  Integration Tests: ${INTEGRATION_TESTS_PASSED} passed, ${INTEGRATION_TESTS_FAILED} failed"
echo "  Coverage: ${COVERAGE_PERCENTAGE}"
echo "  Ops Board: Updated"
echo "  Learnings: Updated"
echo ""
echo -e "$([ ${TESTS_PASSED} = true ] && echo \"${GREEN}Ready for DMX quality review ğŸ”${NC}\" || echo \"${RED}Fix tests before DMX review âš ï¸${NC}\")"
